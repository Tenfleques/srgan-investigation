{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "!pip uninstall -y PyWavelets\n",
    "!pip install PyWavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy, multiprocessing\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from model import get_G, get_D\n",
    "from config import config\n",
    "from PIL import Image\n",
    "\n",
    "import math\n",
    "from random import randrange\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import img_as_float\n",
    "from skimage.measure import compare_ssim as ssim, compare_psnr as psnr\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def evaluate(checkpoint_dir, model, valid_lr_img, valid_hr_img, image_name, G = None, save_dir = \"validation-samples\"):\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    valid_lr_img = (valid_lr_img / 127.5) - 1  # rescale to ［－1, 1]\n",
    "\n",
    "    if not G:\n",
    "        G = get_G([1, None, None, 3])\n",
    "    G.load_weights(os.path.join(checkpoint_dir, model))\n",
    "    G.eval()\n",
    "\n",
    "    valid_lr_img = np.asarray(valid_lr_img, dtype=np.float32)\n",
    "    valid_lr_img = valid_lr_img[np.newaxis,:,:,:]\n",
    "    size = [valid_lr_img.shape[1], valid_lr_img.shape[2]]\n",
    "\n",
    "    out = G(valid_lr_img).numpy()\n",
    "    \n",
    "    model_num = model.replace(\".h5\",\"\").split(\"-\")[1]\n",
    "\n",
    "    print(\"LR size: %s /  generated HR size: %s\" % (size, out.shape))  # LR size: (339, 510, 3) /  gen HR size: (1, 1356, 2040, 3)\n",
    "    \n",
    "    if not os.path.isfile('sr-' + model_num + \"-\" + image_name):\n",
    "        tl.vis.save_image(out[0], os.path.join(save_dir, 'sr-' + model_num + \"-\" + image_name))\n",
    "\n",
    "        out_bicu = scipy.misc.imresize(valid_lr_img[0], [size[0] * 4, size[1] * 4], interp='bicubic', mode=None)\n",
    "        tl.vis.save_image(out_bicu, os.path.join(save_dir, 'bic-' + model_num + \"-\" + image_name))\n",
    "\n",
    "    sr_smaller = tf.image.resize(out[0], size=size)\n",
    "    hr_smaller = tf.image.resize(valid_hr_img, size=size)\n",
    "\n",
    "    validate = {\n",
    "        \"sr\" : out[0],\n",
    "        \"sr_resized\" : sr_smaller.numpy(),\n",
    "        \n",
    "        \"lr\" : valid_lr_img[0],\n",
    "        \"bic\" : out_bicu,\n",
    "        \n",
    "        \"hr\" : valid_hr_img, \n",
    "        \"hr_resized\" : hr_smaller.numpy(),\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"G\" : G,\n",
    "        \n",
    "        \"model\" : model,\n",
    "\n",
    "        \"psnr_lr\" : psnr( validate.get(\"lr\"),  validate.get(\"sr_resized\")),\n",
    "        \"ssim_lr\" : ssim(validate.get(\"lr\"),  validate.get(\"sr_resized\"), multichannel=True),\n",
    "\n",
    "        \"psnr_hr_4\" : psnr( validate.get(\"hr_resized\"),  validate.get(\"sr_resized\"), data_range = 255),\n",
    "        \"ssim_hr_4\" : ssim(validate.get(\"hr_resized\"),  validate.get(\"sr_resized\"), multichannel=True),\n",
    "        \n",
    "        \"psnr_hr\" : psnr( validate.get(\"hr\"),  validate.get(\"sr\")),\n",
    "        \"ssim_hr\" : ssim(validate.get(\"hr\"),  validate.get(\"sr\"), multichannel=True),\n",
    "\n",
    "        \"psnr_bic_hr\" : psnr( validate.get(\"hr\"),  validate.get(\"bic\")),\n",
    "        \"ssim_bic_hr\" : ssim( validate.get(\"hr\"),  validate.get(\"bic\"), multichannel=True),\n",
    "    }\n",
    "    return data\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_downsample(checkpoint_dir, model, valid_hr_img, image_name, G = None, save_dir = \"validation-ds-samples\"):\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    size = [int(valid_hr_img.shape[0]/4), int(valid_hr_img.shape[1]/4)]\n",
    "    \n",
    "    hr_smaller = tf.image.resize(valid_hr_img, size=size)\n",
    "    \n",
    "    valid_lr_img = (hr_smaller / 127.5) - 1  # rescale to ［－1, 1]\n",
    "\n",
    "    if not G:\n",
    "        G = get_G([1, None, None, 3])\n",
    "    G.load_weights(os.path.join(checkpoint_dir, model))\n",
    "    G.eval()\n",
    "\n",
    "    valid_lr_img = np.asarray(valid_lr_img, dtype=np.float32)\n",
    "    valid_lr_img = valid_lr_img[np.newaxis,:,:,:]\n",
    "    \n",
    "\n",
    "    out = G(valid_lr_img).numpy()\n",
    "    \n",
    "    model_num = model.replace(\".h5\",\"\").split(\"-\")[1]\n",
    "\n",
    "    print(\"LR size: %s /  generated HR size: %s\" % (size, out.shape))  # LR size: (339, 510, 3) /  gen HR size: (1, 1356, 2040, 3)\n",
    "    \n",
    "    if not os.path.isfile('sr-' + model_num + \"-\" + image_name):\n",
    "        tl.vis.save_image(out[0], os.path.join(save_dir, 'sr-' + model_num + \"-\" + image_name))\n",
    "\n",
    "        out_bicu = scipy.misc.imresize(valid_lr_img[0], [size[0] * 4, size[1] * 4], interp='bicubic', mode=None)\n",
    "        tl.vis.save_image(out_bicu, os.path.join(save_dir, 'bic-' + model_num + \"-\" + image_name))\n",
    "\n",
    "    sr_smaller = tf.image.resize(out[0], size=size)\n",
    "    \n",
    "\n",
    "    validate = {\n",
    "        \"sr\" : out[0],\n",
    "        \"sr_resized\" : sr_smaller.numpy(),\n",
    "        \n",
    "        \"lr\" : valid_lr_img[0],\n",
    "        \"bic\" : out_bicu,\n",
    "        \n",
    "        \"hr\" : valid_hr_img, \n",
    "        \"hr_resized\" : hr_smaller.numpy(),\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"G\" : G,\n",
    "        \n",
    "        \"model\" : model,\n",
    "\n",
    "        \"psnr_lr\" : psnr( validate.get(\"lr\"),  validate.get(\"sr_resized\")),\n",
    "        \"ssim_lr\" : ssim(validate.get(\"lr\"),  validate.get(\"sr_resized\"), multichannel=True),\n",
    "\n",
    "        \"psnr_hr_4\" : psnr( validate.get(\"hr_resized\"),  validate.get(\"sr_resized\"), data_range = 255),\n",
    "        \"ssim_hr_4\" : ssim(validate.get(\"hr_resized\"),  validate.get(\"sr_resized\"), multichannel=True),\n",
    "        \n",
    "        \"psnr_hr\" : psnr( validate.get(\"hr\"),  validate.get(\"sr\")),\n",
    "        \"ssim_hr\" : ssim(validate.get(\"hr\"),  validate.get(\"sr\"), multichannel=True),\n",
    "\n",
    "        \"psnr_bic_hr\" : psnr( validate.get(\"hr\"),  validate.get(\"bic\")),\n",
    "        \"ssim_bic_hr\" : ssim( validate.get(\"hr\"),  validate.get(\"bic\"), multichannel=True),\n",
    "    }\n",
    "    return data\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] read 20 from DIV2K/DIV2K_valid_LR_difficult/\n",
      "[TL] read 20 from DIV2K/DIV2K_valid_HR/\n"
     ]
    }
   ],
   "source": [
    "###====================== PRE-LOAD DATA ===========================###\n",
    "valid_hr_img_list = sorted(tl.files.load_file_list(path=config.VALID.hr_img_path, regx='.*.png', printable=False))[:20]\n",
    "valid_lr_img_list = sorted(tl.files.load_file_list(path=config.VALID.lr_img_path, regx='.*.png', printable=False))[:20]\n",
    "\n",
    "valid_lr_imgs = tl.vis.read_images(valid_lr_img_list, path=config.VALID.lr_img_path, n_threads=32)\n",
    "\n",
    "valid_hr_imgs = tl.vis.read_images(valid_hr_img_list, path=config.VALID.hr_img_path, n_threads=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPyPlot(validate_data, resized = True):\n",
    "\n",
    "\n",
    "    label = 'SSIM: {:.2f}, sk_psnr:{:.2f} PSNR: {:.2f}'\n",
    "\n",
    "    if resized: # show the images at size == the size of the input LR image\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(17, 12),\n",
    "                             sharex=True, sharey=True)\n",
    "        ax = axes.ravel()\n",
    "        \n",
    "        ax[0].imshow(validate_data.get(\"images\").get(\"lr\"))\n",
    "        ax[0].set_xlabel(label.format(1.00, 100.0, 100.0))\n",
    "        ax[0].set_title('valid LR image')\n",
    "        \n",
    "        ax[1].imshow(validate_data.get(\"images\").get(\"sr_resized\"))\n",
    "        ax[1].set_xlabel(label.format(validate_data.get(\"ssim_lr\"), validate_data.get(\"psnr_lr\"), validate_data.get(\"PSNR_lr\")))\n",
    "        ax[1].set_title('generated image resized *-4 vs LR image')\n",
    "        \n",
    "        ax[2].imshow(validate_data.get(\"images\").get(\"hr_resized\"))\n",
    "        ax[2].set_xlabel(label.format(1.00, 100.0, 100.0))\n",
    "        ax[2].set_title('valid HR resized *-4')      \n",
    "        \n",
    "        ax[3].imshow(validate_data.get(\"images\").get(\"sr_resized\"))\n",
    "        ax[3].set_xlabel(label.format(validate_data.get(\"ssim_hr_4\"), validate_data.get(\"psnr_hr_4\"), validate_data.get(\"PSNR_hr_4\")))\n",
    "        ax[3].set_title('generated image resized *-4 vs HR resized')\n",
    "        \n",
    "    else: \n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(17, 12),\n",
    "                             sharex=True, sharey=True)\n",
    "        ax = axes.ravel()\n",
    "    \n",
    "        ax[0].imshow(validate_data.get(\"images\").get(\"hr\"))\n",
    "        ax[0].set_xlabel(label.format(1.00, 100.0, 100.0))\n",
    "        ax[0].set_title('valid HR image')\n",
    "\n",
    "        ax[1].imshow(validate_data.get(\"images\").get(\"bic\"))\n",
    "        ax[1].set_xlabel(label.format(validate_data.get(\"ssim_bic_hr\"), validate_data.get(\"psnr_bic_hr\"), validate_data.get(\"PSNR_bic_hr\")))\n",
    "        ax[1].set_title('bicubic interpolation *4 vs HR')\n",
    "\n",
    "        ax[2].imshow(validate_data.get(\"images\").get(\"sr\"))\n",
    "        ax[2].set_xlabel(label.format(validate_data.get(\"ssim_hr\"), validate_data.get(\"psnr_hr\"), validate_data.get(\"PSNR_bic_hr\")))\n",
    "        ax[2].set_title('generated image vs HR')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_names(a):\n",
    "    return int(a.replace(\".h5\",\"\").split(\"-\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_three(l):\n",
    "    return [i for i in set((randrange(l), randrange(l), randrange(l), randrange(l), randrange(l)))][:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"g-830-base.h5\", \"g-830-cyclic.h5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "l = len(valid_hr_img_list)\n",
    "\n",
    "for image in rand_three(l):\n",
    "    validate_array = []\n",
    "    for model in models:\n",
    "        valid_lr_img = valid_lr_imgs[image]\n",
    "        valid_hr_img = valid_hr_imgs[image]\n",
    "        image_name = valid_hr_img_list[image]\n",
    "        \n",
    "        ev = evaluate(\"checkpoint\", model, valid_lr_img, valid_hr_img, image_name, G = G)\n",
    "        \n",
    "        G = ev.pop(\"G\", G)\n",
    "        validate_array.append(ev) \n",
    "        \n",
    "    with open(\"logs/\" + image_name + \".json\", mode='w', encoding='utf-8') as f:\n",
    "        json.dump(validate_array, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Input  _inputlayer_1: [1, None, None, 3]\n",
      "[TL] Conv2d conv2d_1: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d_2: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_1: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_3: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_2: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_1: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_4: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_3: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_5: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_4: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_2: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_6: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_5: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_7: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_6: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_3: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_8: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_7: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_9: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_8: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_4: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_10: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_9: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_11: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_10: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_5: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_12: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_11: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_13: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_12: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_6: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_14: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_13: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_15: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_14: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_7: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_16: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_15: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_17: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_16: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_8: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_18: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_17: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_19: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_18: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_9: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_20: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_19: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_21: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_20: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_10: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_22: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_21: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_23: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_22: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_11: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_24: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_23: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_25: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_24: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_12: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_26: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_25: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_27: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_26: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_13: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_28: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_27: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_29: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_28: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_14: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_30: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_29: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_31: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_30: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_15: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_32: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_31: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_33: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_32: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_16: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_34: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_33: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_17: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_35: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] SubpixelConv2d  subpixelconv2d_1: scale: 2 act: relu\n",
      "[TL] Conv2d conv2d_36: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] SubpixelConv2d  subpixelconv2d_2: scale: 2 act: relu\n",
      "[TL] Conv2d conv2d_37: n_filter: 3 filter_size: (1, 1) strides: (1, 1) pad: SAME act: tanh\n",
      "[TL] [*] Load checkpoint/g-830-base.h5 SUCCESS!\n",
      "LR size: [300, 510] /  generated HR size: (1, 1200, 2040, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [-0.974590003490448, 0.9691450595855713]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "/usr/local/lib/python3.6/dist-packages/skimage/measure/simple_metrics.py:127: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im_true.\n",
      "  warn(\"Inputs have mismatched dtype.  Setting data_range based on \"\n",
      "/usr/local/lib/python3.6/dist-packages/skimage/measure/_structural_similarity.py:155: UserWarning: Inputs have mismatched dtype.  Setting data_range based on X.dtype.\n",
      "  warn(\"Inputs have mismatched dtype.  Setting data_range based on \"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dd68217d16e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mev_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_downsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"checkpoint\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"g-830-base.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_hr_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"G\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mev_cyclic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_downsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"checkpoint\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"g-830-cyclic.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_hr_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ev' is not defined"
     ]
    }
   ],
   "source": [
    "l = len(valid_hr_img_list)\n",
    "\n",
    "validate_ds_array_base = []\n",
    "validate_ds_array_cyclic = []\n",
    "\n",
    "for image in rand_three(l):    \n",
    "    valid_hr_img = valid_hr_imgs[image]\n",
    "    image_name = valid_hr_img_list[image]\n",
    "\n",
    "    ev_base = evaluate_downsample(\"checkpoint\", \"g-830-base.h5\", valid_hr_img, image_name, G = G)\n",
    "    G = ev.pop(\"G\", G)\n",
    "    ev_cyclic = evaluate_downsample(\"checkpoint\", \"g-830-cyclic.h5\", valid_hr_img, image_name, G = G)\n",
    "    \n",
    "    validate_ds_array_cyclic.append(ev_cyclic) \n",
    "    validate_ds_array_base.append(ev_base)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.DataFrame(validate_ds_array_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclic = pd.DataFrame(validate_ds_array_cyclic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "createPyPlot(validate, resized = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "createPyPlot(validate, resized = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
