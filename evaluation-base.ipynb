{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting tensorlayer>=2.0.0\n",
      "\u001b[?25l  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/66/7d/80daea9f4359253b76266bc3d4ebd665b5a56eab4117a96d60e63f2182cb/tensorlayer-2.1.0-py2.py3-none-any.whl (353kB)\n",
      "\u001b[K     |████████████████████████████████| 358kB 75.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow>=2.0.0b1\n",
      "\u001b[?25l  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/7b/44/4e8cc8c84cf235628ee919ba97ee029f2d080fa3573e26fe726973d004b4/tensorflow-2.1.0rc2-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8MB 8.1MB/s eta 0:00:0101s eta 0:00:155.6MB 29.4MB/s eta 0:00:14.2MB 29.4MB/s eta 0:00:14141414| 42.1MB 29.4MB/s eta 0:00:13                         | 46.6MB 29.4MB/s eta 0:00:13                         | 51.0MB 29.4MB/s eta 0:00:13.8MB 29.4MB/s eta 0:00:13                     | 61.3MB 29.4MB/s eta 0:00:13               | 66.3MB 29.4MB/s eta 0:00:13��█▍                          | 70.9MB 102.2MB/s eta 0:00:04MB/s eta 0:00:04  | 78.7MB 102.2MB/s eta 0:00:04██▍                         | 84.2MB 102.2MB/s eta 0:00:04        | 89.2MB 102.2MB/s eta 0:00:04��█                         | 93.5MB 102.2MB/s eta 0:00:04MB 102.2MB/s eta 0:00:04                | 102.7MB 102.2MB/s eta 0:00:04                | 106.5MB 102.2MB/s eta 0:00:04040403               | 132.5MB 102.2MB/s eta 0:00:03��██▍                     | 136.8MB 79.8MB/s eta 0:00:04            | 140.9MB 79.8MB/s eta 0:00:04��█████                     | 145.1MB 79.8MB/s eta 0:00:04MB/s eta 0:00:04MB/s eta 0:00:04                  | 158.1MB 79.8MB/s eta 0:00:04.8MB/s eta 0:00:04          | 188.9MB 79.8MB/s eta 0:00:03          | 193.1MB 79.8MB/s eta 0:00:03          | 197.0MB 79.8MB/s eta 0:00:03    |███████████████▎                | 201.1MB 104.4MB/s eta 0:00:03    |███████████████▉                | 209.4MB 104.4MB/s eta 0:00:03��█████▌               | 217.0MB 104.4MB/s eta 0:00:02 |████████████████▊               | 220.3MB 104.4MB/s eta 0:00:02��██████               | 223.6MB 104.4MB/s eta 0:00:02    |█████████████████▏              | 227.0MB 104.4MB/s eta 0:00:02    |█████████████████▌              | 230.3MB 104.4MB/s eta 0:00:02��███████▉              | 234.8MB 104.4MB/s eta 0:00:02��████████              | 237.5MB 104.4MB/s eta 0:00:02[K     |██████████████████▎             | 241.6MB 104.4MB/s eta 0:00:02[K     |██████████████████▋             | 245.5MB 104.4MB/s eta 0:00:02     |███████████████████             | 249.2MB 104.4MB/s eta 0:00:02B 104.4MB/s eta 0:00:02   | 256.4MB 104.4MB/s eta 0:00:02█▊            | 259.4MB 46.3MB/s eta 0:00:04██            | 263.2MB 46.3MB/s eta 0:00:04�           | 266.4MB 46.3MB/s eta 0:00:04�           | 272.7MB 46.3MB/s eta 0:00:04███████████████▏          | 279.6MB 46.3MB/s eta 0:00:04��█████▎          | 281.0MB 46.3MB/s eta 0:00:040:03��█████▉          | 287.5MB 46.3MB/s eta 0:00:03████████████████          | 290.5MB 46.3MB/s eta 0:00:03.3MB/s eta 0:00:03:00:03:00:03:00:03��        | 306.4MB 46.3MB/s eta 0:00:03█████████████▌        | 309.4MB 46.3MB/s eta 0:00:03�███████████▎       | 320.5MB 66.1MB/s eta 0:00:02�███████████▋       | 323.8MB 66.1MB/s eta 0:00:02�███████████▉       | 327.6MB 66.1MB/s eta 0:00:029.0MB 66.1MB/s eta 0:00:02332.3MB 66.1MB/s eta 0:00:02███████████████████████▌      | 335.8MB 66.1MB/s eta 0:00:02��█████████████████▊      | 339.1MB 66.1MB/s eta 0:00:02████████████████████████      | 342.2MB 66.1MB/s eta 0:00:02  | 345.7MB 66.1MB/s eta 0:00:02MB/s eta 0:00:02██████████████▊     | 352.9MB 66.1MB/s eta 0:00:02 | 356.1MB 107.4MB/s eta 0:00:01   |███████████████████████████▎    | 359.4MB 107.4MB/s eta 0:00:01�███████▌    | 363.2MB 107.4MB/s eta 0:00:01�███████▊    | 366.0MB 107.4MB/s eta 0:00:01   |████████████████████████████    | 368.8MB 107.4MB/s eta 0:00:01.3MB 107.4MB/s eta 0:00:01��███████████████████▌   | 375.6MB 107.4MB/s eta 0:00:01.5MB 107.4MB/s eta 0:00:01    |█████████████████████████████▎  | 385.6MB 107.4MB/s eta 0:00:01��█████████████████████████▌  | 388.9MB 107.4MB/s eta 0:00:01�███████████████████████████▊  | 392.3MB 107.4MB/s eta 0:00:01�████████████████████████████  | 395.4MB 107.4MB/s eta 0:00:016MB 107.4MB/s eta 0:00:01█████▍ | 400.0MB 107.4MB/s eta 0:00:014MB 107.4MB/s eta 0:00:015MB 107.4MB/s eta 0:00:01██████ | 408.6MB 107.4MB/s eta 0:00:0116.2MB 8.1MB/s eta 0:00:019.1MB 8.1MB/s eta 0:00:011.8MB 8.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy==1.16.1 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (1.16.1)\n",
      "Processing /home/ma-user/.cache/pip/wheels/b6/e6/d8/7077cdffa066c81ab0594dae71198c9e6d5883ab51f8ba761d/easydict-1.9-cp36-none-any.whl\n",
      "Requirement already satisfied: progressbar2==3.39.3 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from tensorlayer>=2.0.0->-r requirements.txt (line 1)) (3.39.3)\n",
      "Collecting requests==2.21.0\n",
      "\u001b[?25l  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 70.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py>=2.9\n",
      "\u001b[?25l  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 59.4MB/s eta 0:00:01�██████████████████████████▍| 2.8MB 59.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio==2.5.0\n",
      "\u001b[?25l  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/af/0a/943c965d372dae0b1f1482677d29030ab834351a61a9a632fd62f27f1523/imageio-2.5.0-py3-none-any.whl (3.3MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3MB 7.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn==0.21.0 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from tensorlayer>=2.0.0->-r requirements.txt (line 1)) (0.21.0)\n",
      "Collecting scikit-image==0.15.0\n",
      "\u001b[?25l  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/d4/ab/674e168bf7d0bc597218b3bec858d02c23fbac9ec1fec9cad878c6cee95f/scikit_image-0.15.0-cp36-cp36m-manylinux1_x86_64.whl (26.3MB)\n",
      "\u001b[K     |████████████████████████████████| 26.3MB 14.2MB/s eta 0:00:01         | 3.0MB 14.2MB/s eta 0:00:02 eta 0:00:02��██████▉                   | 10.5MB 14.2MB/s eta 0:00:02| 14.1MB 14.2MB/s eta 0:00:01     | 17.3MB 14.2MB/s eta 0:00:01███████▌      | 21.0MB 14.2MB/s eta 0:00:014.4MB 14.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy==1.2.1 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from tensorlayer>=2.0.0->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: cloudpickle>=0.8.1 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from tensorlayer>=2.0.0->-r requirements.txt (line 1)) (1.2.2)\n",
      "Processing /home/ma-user/.cache/pip/wheels/42/07/8a/d5a4077acf843791673a5392a02e26ccd592738b577b7d2ffc/wrapt-1.11.1-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting keras-applications>=1.0.8\n",
      "\u001b[?25l  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 73.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (1.26.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (0.2.2)\n",
      "Processing /home/ma-user/.cache/pip/wheels/2e/a6/d2/6d32f50968db82163ec5820a3c6d2b75d35274458a0932f192/opt_einsum-3.1.0-cp36-none-any.whl\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (0.1.8)\n",
      "Collecting protobuf>=3.8.0\n",
      "\u001b[?25l  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/ca/ac/838c8c8a5f33a58132dd2ad2a30329f6ae1614a9f56ffb79eaaf71a9d156/protobuf-3.11.2-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 1.3MB 51.7MB/s eta 0:00:01��████▋                     | 419kB 51.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "\u001b[?25l  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 43.5MB/s eta 0:00:01/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ma-user/anaconda3/lib/python3.6/site-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (0.30.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (1.13.0)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "\u001b[?25l  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 53.4MB/s eta 0:00:01s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-utils>=2.3.0 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from progressbar2==3.39.3->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from requests==2.21.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from requests==2.21.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from requests==2.21.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from requests==2.21.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (2018.1.18)\n",
      "Requirement already satisfied: pillow in /home/ma-user/anaconda3/lib/python3.6/site-packages (from imageio==2.5.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (6.2.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from scikit-learn==0.21.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (0.14.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from scikit-image==0.15.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (2.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from scikit-image==0.15.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from scikit-image==0.15.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /home/ma-user/anaconda3/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (41.0.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (0.14.1)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "\u001b[?25l  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/36/f8/84b5771faec3eba9fe0c91c8c5896364a8ba08852c0dea5ad2025026dd95/google_auth-1.10.0-py2.py3-none-any.whl (76kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 77.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.1.0 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from networkx>=2.0->scikit-image==0.15.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (4.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.0 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ma-user/anaconda3/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: pytz in /home/ma-user/anaconda3/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (2019.3)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "\u001b[?25l  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/52/50/bb4cefca37da63a0c52218ba2cb1b1c36110d84dcbae8aa48cd67c5e95c2/pyasn1_modules-0.2.7-py2.py3-none-any.whl (131kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 82.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "\u001b[?25l  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 67.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1>=0.1.3\n",
      "\u001b[?25l  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 76.8MB/s eta 0:00:01\n",
      "\u001b[31mERROR: modelarts 1.1.3 has requirement Flask==1.0.2, but you'll have flask 0.12.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: modelarts 1.1.3 has requirement Flask-Cors==3.0.4, but you'll have flask-cors 3.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: modelarts 1.1.3 has requirement psutil==5.4.6, but you'll have psutil 5.4.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: modelarts 1.1.3 has requirement urllib3==1.21.1, but you'll have urllib3 1.22 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.1.0rc2 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.2.1 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: requests, h5py, imageio, scikit-image, wrapt, tensorlayer, keras-applications, opt-einsum, protobuf, tensorflow-estimator, astor, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow, easydict\n",
      "  Found existing installation: requests 2.18.4\n",
      "    Uninstalling requests-2.18.4:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Successfully uninstalled requests-2.18.4\n",
      "  Found existing installation: h5py 2.8.0\n",
      "    Uninstalling h5py-2.8.0:\n",
      "      Successfully uninstalled h5py-2.8.0\n",
      "  Found existing installation: imageio 2.2.0\n",
      "\u001b[31mERROR: Cannot uninstall 'imageio'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y PyWavelets\n",
    "!pip install PyWavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y Pillow\n",
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy, multiprocessing\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from model import get_G, get_D\n",
    "from config import config\n",
    "from PIL import Image\n",
    "\n",
    "import math\n",
    "from random import randrange\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import img_as_float\n",
    "from skimage.measure import compare_ssim as ssim, compare_psnr as psnr\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(checkpoint_dir, model, valid_lr_img, valid_hr_img, image_name, G = None, save_dir = \"validation-samples\"):\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    valid_lr_img = (valid_lr_img / 127.5) - 1  # rescale to ［－1, 1]\n",
    "\n",
    "    if not G:\n",
    "        G = get_G([1, None, None, 3])\n",
    "        G.load_weights(os.path.join(checkpoint_dir, model))\n",
    "        G.eval()\n",
    "\n",
    "    valid_lr_img = np.asarray(valid_lr_img, dtype=np.float32)\n",
    "    valid_lr_img = valid_lr_img[np.newaxis,:,:,:]\n",
    "    size = [valid_lr_img.shape[1], valid_lr_img.shape[2]]\n",
    "\n",
    "    out = G(valid_lr_img).numpy()\n",
    "    \n",
    "    model_num = model.replace(\".h5\",\"\").split(\"-\")[1]\n",
    "\n",
    "    print(\"LR size: %s /  generated HR size: %s\" % (size, out.shape))  # LR size: (339, 510, 3) /  gen HR size: (1, 1356, 2040, 3)\n",
    "    \n",
    "    if not os.path.isfile('sr-' + model_num + \"-\" + image_name):\n",
    "        tl.vis.save_image(out[0], os.path.join(save_dir, 'sr-' + model_num + \"-\" + image_name))\n",
    "\n",
    "        out_bicu = scipy.misc.imresize(valid_lr_img[0], [size[0] * 4, size[1] * 4], interp='bicubic', mode=None)\n",
    "        tl.vis.save_image(out_bicu, os.path.join(save_dir, 'bic-' + model_num + \"-\" + image_name))\n",
    "\n",
    "    sr_smaller = tf.image.resize(out[0], size=size)\n",
    "    hr_smaller = tf.image.resize(valid_hr_img, size=size)\n",
    "\n",
    "    validate = {\n",
    "        \"sr\" : out[0],\n",
    "        \"sr_resized\" : sr_smaller.numpy(),\n",
    "        \n",
    "        \"lr\" : valid_lr_img[0],\n",
    "        \"bic\" : out_bicu,\n",
    "        \n",
    "        \"hr\" : valid_hr_img, \n",
    "        \"hr_resized\" : hr_smaller.numpy(),\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"G\" : G,\n",
    "        \n",
    "        \"model\" : model,\n",
    "\n",
    "        \"psnr_lr\" : psnr( validate.get(\"lr\"),  validate.get(\"sr_resized\")),\n",
    "        \"ssim_lr\" : ssim(validate.get(\"lr\"),  validate.get(\"sr_resized\"), multichannel=True),\n",
    "\n",
    "        \"psnr_hr_4\" : psnr( validate.get(\"hr_resized\"),  validate.get(\"sr_resized\"), data_range = 255),\n",
    "        \"ssim_hr_4\" : ssim(validate.get(\"hr_resized\"),  validate.get(\"sr_resized\"), multichannel=True),\n",
    "        \n",
    "        \"psnr_hr\" : psnr( validate.get(\"hr\"),  validate.get(\"sr\")),\n",
    "        \"ssim_hr\" : ssim(validate.get(\"hr\"),  validate.get(\"sr\"), multichannel=True),\n",
    "\n",
    "        \"psnr_bic_hr\" : psnr( validate.get(\"hr\"),  validate.get(\"bic\")),\n",
    "        \"ssim_bic_hr\" : ssim( validate.get(\"hr\"),  validate.get(\"bic\"), multichannel=True),\n",
    "    }\n",
    "    return data\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_downsample(checkpoint_dir, model, valid_hr_img, image_name, G = None, save_dir = \"validation-ds-samples\"):\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    size = [int(valid_hr_img.shape[0]/4), int(valid_hr_img.shape[1]/4)]\n",
    "    \n",
    "    hr_smaller = tf.image.resize(valid_hr_img, size=size)\n",
    "    \n",
    "    valid_lr_img = (hr_smaller / 127.5) - 1  # rescale to ［－1, 1]\n",
    "\n",
    "    if not G:\n",
    "        G = get_G([1, None, None, 3])\n",
    "        G.load_weights(os.path.join(checkpoint_dir, model))\n",
    "        G.eval()\n",
    "\n",
    "    valid_lr_img = np.asarray(valid_lr_img, dtype=np.float32)\n",
    "    valid_lr_img = valid_lr_img[np.newaxis,:,:,:]\n",
    "    \n",
    "\n",
    "    out = G(valid_lr_img).numpy()\n",
    "    \n",
    "    model_num = model.replace(\".h5\",\"\").split(\"-\")[1]\n",
    "\n",
    "    print(\"LR size: %s /  generated HR size: %s\" % (size, out.shape))  # LR size: (339, 510, 3) /  gen HR size: (1, 1356, 2040, 3)\n",
    "    \n",
    "    if not os.path.isfile('sr-' + model_num + \"-\" + image_name):\n",
    "        tl.vis.save_image(out[0], os.path.join(save_dir, 'sr-' + model_num + \"-\" + image_name))\n",
    "\n",
    "        out_bicu = scipy.misc.imresize(valid_lr_img[0], [size[0] * 4, size[1] * 4], interp='bicubic', mode=None)\n",
    "        tl.vis.save_image(out_bicu, os.path.join(save_dir, 'bic-' + model_num + \"-\" + image_name))\n",
    "\n",
    "    sr_smaller = tf.image.resize(out[0], size=size)\n",
    "    \n",
    "\n",
    "    validate = {\n",
    "        \"sr\" : out[0],\n",
    "        \"sr_resized\" : sr_smaller.numpy(),\n",
    "        \n",
    "        \"lr\" : valid_lr_img[0],\n",
    "        \"bic\" : out_bicu,\n",
    "        \n",
    "        \"hr\" : valid_hr_img, \n",
    "        \"hr_resized\" : hr_smaller.numpy(),\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"G\" : G,\n",
    "        \n",
    "        \"model\" : model,\n",
    "\n",
    "        \"psnr_lr\" : psnr( validate.get(\"lr\"),  validate.get(\"sr_resized\")),\n",
    "        \"ssim_lr\" : ssim(validate.get(\"lr\"),  validate.get(\"sr_resized\"), multichannel=True),\n",
    "\n",
    "        \"psnr_hr_4\" : psnr( validate.get(\"hr_resized\"),  validate.get(\"sr_resized\"), data_range = 255),\n",
    "        \"ssim_hr_4\" : ssim(validate.get(\"hr_resized\"),  validate.get(\"sr_resized\"), multichannel=True),\n",
    "        \n",
    "        \"psnr_hr\" : psnr( validate.get(\"hr\"),  validate.get(\"sr\")),\n",
    "        \"ssim_hr\" : ssim(validate.get(\"hr\"),  validate.get(\"sr\"), multichannel=True),\n",
    "\n",
    "        \"psnr_bic_hr\" : psnr( validate.get(\"hr\"),  validate.get(\"bic\")),\n",
    "        \"ssim_bic_hr\" : ssim( validate.get(\"hr\"),  validate.get(\"bic\"), multichannel=True),\n",
    "    }\n",
    "    return data\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###====================== PRE-LOAD DATA ===========================###\n",
    "valid_hr_img_list = sorted(tl.files.load_file_list(path=config.VALID.hr_img_path, regx='.*.png', printable=False))\n",
    "valid_lr_img_list = sorted(tl.files.load_file_list(path=config.VALID.lr_img_path, regx='.*.png', printable=False))\n",
    "\n",
    "valid_lr_imgs = tl.vis.read_images(valid_lr_img_list, path=config.VALID.lr_img_path, n_threads=32)\n",
    "\n",
    "valid_hr_imgs = tl.vis.read_images(valid_hr_img_list, path=config.VALID.hr_img_path, n_threads=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPyPlot(validate_data, resized = True):\n",
    "\n",
    "\n",
    "    label = 'SSIM: {:.2f}, sk_psnr:{:.2f} PSNR: {:.2f}'\n",
    "\n",
    "    if resized: # show the images at size == the size of the input LR image\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(17, 12),\n",
    "                             sharex=True, sharey=True)\n",
    "        ax = axes.ravel()\n",
    "        \n",
    "        ax[0].imshow(validate_data.get(\"images\").get(\"lr\"))\n",
    "        ax[0].set_xlabel(label.format(1.00, 100.0, 100.0))\n",
    "        ax[0].set_title('valid LR image')\n",
    "        \n",
    "        ax[1].imshow(validate_data.get(\"images\").get(\"sr_resized\"))\n",
    "        ax[1].set_xlabel(label.format(validate_data.get(\"ssim_lr\"), validate_data.get(\"psnr_lr\"), validate_data.get(\"PSNR_lr\")))\n",
    "        ax[1].set_title('generated image resized *-4 vs LR image')\n",
    "        \n",
    "        ax[2].imshow(validate_data.get(\"images\").get(\"hr_resized\"))\n",
    "        ax[2].set_xlabel(label.format(1.00, 100.0, 100.0))\n",
    "        ax[2].set_title('valid HR resized *-4')      \n",
    "        \n",
    "        ax[3].imshow(validate_data.get(\"images\").get(\"sr_resized\"))\n",
    "        ax[3].set_xlabel(label.format(validate_data.get(\"ssim_hr_4\"), validate_data.get(\"psnr_hr_4\"), validate_data.get(\"PSNR_hr_4\")))\n",
    "        ax[3].set_title('generated image resized *-4 vs HR resized')\n",
    "        \n",
    "    else: \n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(17, 12),\n",
    "                             sharex=True, sharey=True)\n",
    "        ax = axes.ravel()\n",
    "    \n",
    "        ax[0].imshow(validate_data.get(\"images\").get(\"hr\"))\n",
    "        ax[0].set_xlabel(label.format(1.00, 100.0, 100.0))\n",
    "        ax[0].set_title('valid HR image')\n",
    "\n",
    "        ax[1].imshow(validate_data.get(\"images\").get(\"bic\"))\n",
    "        ax[1].set_xlabel(label.format(validate_data.get(\"ssim_bic_hr\"), validate_data.get(\"psnr_bic_hr\"), validate_data.get(\"PSNR_bic_hr\")))\n",
    "        ax[1].set_title('bicubic interpolation *4 vs HR')\n",
    "\n",
    "        ax[2].imshow(validate_data.get(\"images\").get(\"sr\"))\n",
    "        ax[2].set_xlabel(label.format(validate_data.get(\"ssim_hr\"), validate_data.get(\"psnr_hr\"), validate_data.get(\"PSNR_bic_hr\")))\n",
    "        ax[2].set_title('generated image vs HR')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_names(a):\n",
    "    return int(a.replace(\".h5\",\"\").split(\"-\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_three(l):\n",
    "    return [i for i in set((randrange(l), randrange(l), randrange(l), randrange(l), randrange(l)))][:3]\n",
    "\n",
    "rand_three(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = sorted(tl.files.load_file_list(path=\"checkpoint\", regx='g-[0-9]+\\.(h5)', printable=False), key=compare_models_names)\n",
    "pd.DataFrame(models).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "l = len(valid_hr_img_list)\n",
    "\n",
    "for image in rand_three(l):\n",
    "    validate_array = []\n",
    "    for model in models:\n",
    "        valid_lr_img = valid_lr_imgs[image]\n",
    "        valid_hr_img = valid_hr_imgs[image]\n",
    "        image_name = valid_hr_img_list[image]\n",
    "        \n",
    "        ev = evaluate(\"checkpoint\", model, valid_lr_img, valid_hr_img, image_name, G = G)\n",
    "        \n",
    "        G = ev.pop(\"G\", G)\n",
    "        validate_array.append(ev) \n",
    "        \n",
    "    with open(\"logs/\" + image_name + \".json\", mode='w', encoding='utf-8') as f:\n",
    "        json.dump(validate_array, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(valid_hr_img_list)\n",
    "\n",
    "for image in rand_three(l):\n",
    "    validate_ds_array = []\n",
    "    for model in models:\n",
    "        valid_hr_img = valid_hr_imgs[image]\n",
    "        image_name = valid_hr_img_list[image]\n",
    "        \n",
    "        ev = evaluate_downsample(\"checkpoint\", model, valid_hr_img, image_name, G = G)\n",
    "        \n",
    "        G = ev.pop(\"G\", G)\n",
    "        validate_ds_array.append(ev) \n",
    "        \n",
    "    with open(\"logs/\" + image_name + \"-ds.json\", mode='w', encoding='utf-8') as f:\n",
    "        json.dump(validate_ds_array, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(validate_ds_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda-python3",
   "language": "python",
   "name": "conda-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
