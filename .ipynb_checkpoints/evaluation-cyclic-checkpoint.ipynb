{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y PyWavelets\n",
    "!pip install PyWavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y Pillow\n",
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy, multiprocessing\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from model import get_G, get_D\n",
    "from config import config\n",
    "from PIL import Image\n",
    "\n",
    "import math\n",
    "from random import randrange\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import img_as_float\n",
    "from skimage.measure import compare_ssim as ssim, compare_psnr as psnr\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(checkpoint_dir, model, valid_lr_img, valid_hr_img, image_name, G = None, save_dir = \"validation-samples\"):\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    valid_lr_img = (valid_lr_img / 127.5) - 1  # rescale to ［－1, 1]\n",
    "\n",
    "    if not G:\n",
    "        G = get_G([1, None, None, 3])\n",
    "        G.load_weights(os.path.join(checkpoint_dir, model))\n",
    "        G.eval()\n",
    "\n",
    "    valid_lr_img = np.asarray(valid_lr_img, dtype=np.float32)\n",
    "    valid_lr_img = valid_lr_img[np.newaxis,:,:,:]\n",
    "    size = [valid_lr_img.shape[1], valid_lr_img.shape[2]]\n",
    "\n",
    "    out = G(valid_lr_img).numpy()\n",
    "    \n",
    "    model_num = model.replace(\".h5\",\"\").split(\"-\")[1]\n",
    "\n",
    "    print(\"LR size: %s /  generated HR size: %s\" % (size, out.shape))  # LR size: (339, 510, 3) /  gen HR size: (1, 1356, 2040, 3)\n",
    "    \n",
    "    if not os.path.isfile('sr-' + model_num + \"-\" + image_name):\n",
    "        tl.vis.save_image(out[0], os.path.join(save_dir, 'sr-' + model_num + \"-\" + image_name))\n",
    "\n",
    "        out_bicu = scipy.misc.imresize(valid_lr_img[0], [size[0] * 4, size[1] * 4], interp='bicubic', mode=None)\n",
    "        tl.vis.save_image(out_bicu, os.path.join(save_dir, 'bic-' + model_num + \"-\" + image_name))\n",
    "\n",
    "    sr_smaller = tf.image.resize(out[0], size=size)\n",
    "    hr_smaller = tf.image.resize(valid_hr_img, size=size)\n",
    "\n",
    "    validate = {\n",
    "        \"sr\" : out[0],\n",
    "        \"sr_resized\" : sr_smaller.numpy(),\n",
    "        \n",
    "        \"lr\" : valid_lr_img[0],\n",
    "        \"bic\" : out_bicu,\n",
    "        \n",
    "        \"hr\" : valid_hr_img, \n",
    "        \"hr_resized\" : hr_smaller.numpy(),\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"G\" : G,\n",
    "        \n",
    "        \"model\" : model,\n",
    "\n",
    "        \"psnr_lr\" : psnr( validate.get(\"lr\"),  validate.get(\"sr_resized\")),\n",
    "        \"ssim_lr\" : ssim(validate.get(\"lr\"),  validate.get(\"sr_resized\"), multichannel=True),\n",
    "\n",
    "        \"psnr_hr_4\" : psnr( validate.get(\"hr_resized\"),  validate.get(\"sr_resized\"), data_range = 255),\n",
    "        \"ssim_hr_4\" : ssim(validate.get(\"hr_resized\"),  validate.get(\"sr_resized\"), multichannel=True),\n",
    "        \n",
    "        \"psnr_hr\" : psnr( validate.get(\"hr\"),  validate.get(\"sr\")),\n",
    "        \"ssim_hr\" : ssim(validate.get(\"hr\"),  validate.get(\"sr\"), multichannel=True),\n",
    "\n",
    "        \"psnr_bic_hr\" : psnr( validate.get(\"hr\"),  validate.get(\"bic\")),\n",
    "        \"ssim_bic_hr\" : ssim( validate.get(\"hr\"),  validate.get(\"bic\"), multichannel=True),\n",
    "    }\n",
    "    return data\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_downsample(checkpoint_dir, model, valid_hr_img, image_name, G = None, save_dir = \"validation-ds-samples\"):\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    size = [int(valid_hr_img.shape[0]/4), int(valid_hr_img.shape[1]/4)]\n",
    "    \n",
    "    hr_smaller = tf.image.resize(valid_hr_img, size=size)\n",
    "    \n",
    "    valid_lr_img = (hr_smaller / 127.5) - 1  # rescale to ［－1, 1]\n",
    "\n",
    "    if not G:\n",
    "        G = get_G([1, None, None, 3])\n",
    "        G.load_weights(os.path.join(checkpoint_dir, model))\n",
    "        G.eval()\n",
    "\n",
    "    valid_lr_img = np.asarray(valid_lr_img, dtype=np.float32)\n",
    "    valid_lr_img = valid_lr_img[np.newaxis,:,:,:]\n",
    "    \n",
    "\n",
    "    out = G(valid_lr_img).numpy()\n",
    "    \n",
    "    model_num = model.replace(\".h5\",\"\").split(\"-\")[1]\n",
    "\n",
    "    print(\"LR size: %s /  generated HR size: %s\" % (size, out.shape))  # LR size: (339, 510, 3) /  gen HR size: (1, 1356, 2040, 3)\n",
    "    \n",
    "    if not os.path.isfile('sr-' + model_num + \"-\" + image_name):\n",
    "        tl.vis.save_image(out[0], os.path.join(save_dir, 'sr-' + model_num + \"-\" + image_name))\n",
    "\n",
    "        out_bicu = scipy.misc.imresize(valid_lr_img[0], [size[0] * 4, size[1] * 4], interp='bicubic', mode=None)\n",
    "        tl.vis.save_image(out_bicu, os.path.join(save_dir, 'bic-' + model_num + \"-\" + image_name))\n",
    "\n",
    "    sr_smaller = tf.image.resize(out[0], size=size)\n",
    "    \n",
    "\n",
    "    validate = {\n",
    "        \"sr\" : out[0],\n",
    "        \"sr_resized\" : sr_smaller.numpy(),\n",
    "        \n",
    "        \"lr\" : valid_lr_img[0],\n",
    "        \"bic\" : out_bicu,\n",
    "        \n",
    "        \"hr\" : valid_hr_img, \n",
    "        \"hr_resized\" : hr_smaller.numpy(),\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"G\" : G,\n",
    "        \n",
    "        \"model\" : model,\n",
    "\n",
    "        \"psnr_lr\" : psnr( validate.get(\"lr\"),  validate.get(\"sr_resized\")),\n",
    "        \"ssim_lr\" : ssim(validate.get(\"lr\"),  validate.get(\"sr_resized\"), multichannel=True),\n",
    "\n",
    "        \"psnr_hr_4\" : psnr( validate.get(\"hr_resized\"),  validate.get(\"sr_resized\"), data_range = 255),\n",
    "        \"ssim_hr_4\" : ssim(validate.get(\"hr_resized\"),  validate.get(\"sr_resized\"), multichannel=True),\n",
    "        \n",
    "        \"psnr_hr\" : psnr( validate.get(\"hr\"),  validate.get(\"sr\")),\n",
    "        \"ssim_hr\" : ssim(validate.get(\"hr\"),  validate.get(\"sr\"), multichannel=True),\n",
    "\n",
    "        \"psnr_bic_hr\" : psnr( validate.get(\"hr\"),  validate.get(\"bic\")),\n",
    "        \"ssim_bic_hr\" : ssim( validate.get(\"hr\"),  validate.get(\"bic\"), multichannel=True),\n",
    "    }\n",
    "    return data\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###====================== PRE-LOAD DATA ===========================###\n",
    "valid_hr_img_list = sorted(tl.files.load_file_list(path=config.VALID.hr_img_path, regx='.*.png', printable=False))\n",
    "valid_lr_img_list = sorted(tl.files.load_file_list(path=config.VALID.lr_img_path, regx='.*.png', printable=False))\n",
    "\n",
    "valid_lr_imgs = tl.vis.read_images(valid_lr_img_list, path=config.VALID.lr_img_path, n_threads=32)\n",
    "\n",
    "valid_hr_imgs = tl.vis.read_images(valid_hr_img_list, path=config.VALID.hr_img_path, n_threads=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPyPlot(validate_data, resized = True):\n",
    "\n",
    "\n",
    "    label = 'SSIM: {:.2f}, sk_psnr:{:.2f} PSNR: {:.2f}'\n",
    "\n",
    "    if resized: # show the images at size == the size of the input LR image\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(17, 12),\n",
    "                             sharex=True, sharey=True)\n",
    "        ax = axes.ravel()\n",
    "        \n",
    "        ax[0].imshow(validate_data.get(\"images\").get(\"lr\"))\n",
    "        ax[0].set_xlabel(label.format(1.00, 100.0, 100.0))\n",
    "        ax[0].set_title('valid LR image')\n",
    "        \n",
    "        ax[1].imshow(validate_data.get(\"images\").get(\"sr_resized\"))\n",
    "        ax[1].set_xlabel(label.format(validate_data.get(\"ssim_lr\"), validate_data.get(\"psnr_lr\"), validate_data.get(\"PSNR_lr\")))\n",
    "        ax[1].set_title('generated image resized *-4 vs LR image')\n",
    "        \n",
    "        ax[2].imshow(validate_data.get(\"images\").get(\"hr_resized\"))\n",
    "        ax[2].set_xlabel(label.format(1.00, 100.0, 100.0))\n",
    "        ax[2].set_title('valid HR resized *-4')      \n",
    "        \n",
    "        ax[3].imshow(validate_data.get(\"images\").get(\"sr_resized\"))\n",
    "        ax[3].set_xlabel(label.format(validate_data.get(\"ssim_hr_4\"), validate_data.get(\"psnr_hr_4\"), validate_data.get(\"PSNR_hr_4\")))\n",
    "        ax[3].set_title('generated image resized *-4 vs HR resized')\n",
    "        \n",
    "    else: \n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(17, 12),\n",
    "                             sharex=True, sharey=True)\n",
    "        ax = axes.ravel()\n",
    "    \n",
    "        ax[0].imshow(validate_data.get(\"images\").get(\"hr\"))\n",
    "        ax[0].set_xlabel(label.format(1.00, 100.0, 100.0))\n",
    "        ax[0].set_title('valid HR image')\n",
    "\n",
    "        ax[1].imshow(validate_data.get(\"images\").get(\"bic\"))\n",
    "        ax[1].set_xlabel(label.format(validate_data.get(\"ssim_bic_hr\"), validate_data.get(\"psnr_bic_hr\"), validate_data.get(\"PSNR_bic_hr\")))\n",
    "        ax[1].set_title('bicubic interpolation *4 vs HR')\n",
    "\n",
    "        ax[2].imshow(validate_data.get(\"images\").get(\"sr\"))\n",
    "        ax[2].set_xlabel(label.format(validate_data.get(\"ssim_hr\"), validate_data.get(\"psnr_hr\"), validate_data.get(\"PSNR_bic_hr\")))\n",
    "        ax[2].set_title('generated image vs HR')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_names(a):\n",
    "    return int(a.replace(\".h5\",\"\").split(\"-\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_three(l):\n",
    "    return [i for i in set((randrange(l), randrange(l), randrange(l), randrange(l), randrange(l)))][:3]\n",
    "\n",
    "rand_three(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = sorted(tl.files.load_file_list(path=\"checkpoint\", regx='g-[0-9]+\\.(h5)', printable=False), key=compare_models_names)\n",
    "pd.DataFrame(models).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "l = len(valid_hr_img_list)\n",
    "\n",
    "for image in rand_three(l):\n",
    "    validate_array = []\n",
    "    for model in models:\n",
    "        valid_lr_img = valid_lr_imgs[image]\n",
    "        valid_hr_img = valid_hr_imgs[image]\n",
    "        image_name = valid_hr_img_list[image]\n",
    "        \n",
    "        ev = evaluate(\"checkpoint\", model, valid_lr_img, valid_hr_img, image_name, G = G)\n",
    "        \n",
    "        G = ev.pop(\"G\", G)\n",
    "        validate_array.append(ev) \n",
    "        \n",
    "    with open(\"logs/\" + image_name + \".json\", mode='w', encoding='utf-8') as f:\n",
    "        json.dump(validate_array, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(valid_hr_img_list)\n",
    "\n",
    "for image in rand_three(l):\n",
    "    validate_ds_array = []\n",
    "    for model in models:\n",
    "        valid_hr_img = valid_hr_imgs[image]\n",
    "        image_name = valid_hr_img_list[image]\n",
    "        \n",
    "        ev = evaluate_downsample(\"checkpoint\", model, valid_hr_img, image_name, G = G)\n",
    "        \n",
    "        G = ev.pop(\"G\", G)\n",
    "        validate_ds_array.append(ev) \n",
    "        \n",
    "    with open(\"logs/\" + image_name + \"-ds.json\", mode='w', encoding='utf-8') as f:\n",
    "        json.dump(validate_ds_array, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(validate_ds_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda-python3",
   "language": "python",
   "name": "conda-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
