{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "!pip uninstall -y PyWavelets\n",
    "!pip install PyWavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy, multiprocessing\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from model import get_G, get_D\n",
    "from config import config\n",
    "from PIL import Image\n",
    "\n",
    "import math\n",
    "from random import randrange\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import img_as_float\n",
    "from skimage.measure import compare_ssim as ssim, compare_psnr as psnr\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def evaluate(checkpoint_dir, model, valid_lr_img, valid_hr_img, image_name, G = None, save_dir = \"validation-samples\"):\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    valid_lr_img = (valid_lr_img / 127.5) - 1  # rescale to ［－1, 1]\n",
    "\n",
    "    if not G:\n",
    "        G = get_G([1, None, None, 3])\n",
    "    G.load_weights(os.path.join(checkpoint_dir, model))\n",
    "    G.eval()\n",
    "\n",
    "    valid_lr_img = np.asarray(valid_lr_img, dtype=np.float32)\n",
    "    valid_lr_img = valid_lr_img[np.newaxis,:,:,:]\n",
    "    size = [valid_lr_img.shape[1], valid_lr_img.shape[2]]\n",
    "\n",
    "    out = G(valid_lr_img).numpy()\n",
    "    \n",
    "    model_num = model.replace(\".h5\",\"\").split(\"-\")[1]\n",
    "\n",
    "    print(\"LR size: %s /  generated HR size: %s\" % (size, out.shape))  # LR size: (339, 510, 3) /  gen HR size: (1, 1356, 2040, 3)\n",
    "    \n",
    "    if not os.path.isfile('sr-' + model_num + \"-\" + image_name):\n",
    "        tl.vis.save_image(out[0], os.path.join(save_dir, 'sr-' + model_num + \"-\" + image_name))\n",
    "\n",
    "        out_bicu = scipy.misc.imresize(valid_lr_img[0], [size[0] * 4, size[1] * 4], interp='bicubic', mode=None)\n",
    "        tl.vis.save_image(out_bicu, os.path.join(save_dir, 'bic-' + model_num + \"-\" + image_name))\n",
    "\n",
    "    sr_smaller = tf.image.resize(out[0], size=size)\n",
    "    hr_smaller = tf.image.resize(valid_hr_img, size=size)\n",
    "\n",
    "    validate = {\n",
    "        \"sr\" : out[0],\n",
    "        \"sr_resized\" : sr_smaller.numpy(),\n",
    "        \n",
    "        \"lr\" : valid_lr_img[0],\n",
    "        \"bic\" : out_bicu,\n",
    "        \n",
    "        \"hr\" : valid_hr_img, \n",
    "        \"hr_resized\" : hr_smaller.numpy(),\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"G\" : G,\n",
    "        \n",
    "        \"model\" : model,\n",
    "\n",
    "        \"psnr_lr\" : psnr( validate.get(\"lr\"),  validate.get(\"sr_resized\")),\n",
    "        \"ssim_lr\" : ssim(validate.get(\"lr\"),  validate.get(\"sr_resized\"), multichannel=True),\n",
    "\n",
    "        \"psnr_hr_4\" : psnr( validate.get(\"hr_resized\"),  validate.get(\"sr_resized\"), data_range = 255),\n",
    "        \"ssim_hr_4\" : ssim(validate.get(\"hr_resized\"),  validate.get(\"sr_resized\"), multichannel=True),\n",
    "        \n",
    "        \"psnr_hr\" : psnr( validate.get(\"hr\"),  validate.get(\"sr\")),\n",
    "        \"ssim_hr\" : ssim(validate.get(\"hr\"),  validate.get(\"sr\"), multichannel=True),\n",
    "\n",
    "        \"psnr_bic_hr\" : psnr( validate.get(\"hr\"),  validate.get(\"bic\")),\n",
    "        \"ssim_bic_hr\" : ssim( validate.get(\"hr\"),  validate.get(\"bic\"), multichannel=True),\n",
    "    }\n",
    "    return data\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_downsample(checkpoint_dir, model, valid_hr_img, image_name, G = None, save_dir = \"validation-ds-samples\"):\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    size = [int(valid_hr_img.shape[0]/4), int(valid_hr_img.shape[1]/4)]\n",
    "    \n",
    "    hr_smaller = tf.image.resize(valid_hr_img, size=size)\n",
    "    \n",
    "    valid_lr_img = (hr_smaller / 127.5) - 1  # rescale to ［－1, 1]\n",
    "\n",
    "    if not G:\n",
    "        G = get_G([1, None, None, 3])\n",
    "    G.load_weights(os.path.join(checkpoint_dir, model))\n",
    "    G.eval()\n",
    "\n",
    "    valid_lr_img = np.asarray(valid_lr_img, dtype=np.float32)\n",
    "    valid_lr_img = valid_lr_img[np.newaxis,:,:,:]\n",
    "    \n",
    "\n",
    "    out = G(valid_lr_img).numpy()\n",
    "    \n",
    "    model_num = model.replace(\".h5\",\"\").split(\"-\")[1]\n",
    "\n",
    "    print(\"LR size: %s /  generated HR size: %s\" % (size, out.shape))  # LR size: (339, 510, 3) /  gen HR size: (1, 1356, 2040, 3)\n",
    "    \n",
    "    if not os.path.isfile('sr-' + model_num + \"-\" + image_name):\n",
    "        tl.vis.save_image(out[0], os.path.join(save_dir, 'sr-' + model_num + \"-\" + image_name))\n",
    "\n",
    "        out_bicu = scipy.misc.imresize(valid_lr_img[0], [size[0] * 4, size[1] * 4], interp='bicubic', mode=None)\n",
    "        tl.vis.save_image(out_bicu, os.path.join(save_dir, 'bic-' + model_num + \"-\" + image_name))\n",
    "\n",
    "    sr_smaller = tf.image.resize(out[0], size=size)\n",
    "    \n",
    "\n",
    "    validate = {\n",
    "        \"sr\" : out[0],\n",
    "        \"sr_resized\" : sr_smaller.numpy(),\n",
    "        \n",
    "        \"lr\" : valid_lr_img[0],\n",
    "        \"bic\" : out_bicu,\n",
    "        \n",
    "        \"hr\" : valid_hr_img, \n",
    "        \"hr_resized\" : hr_smaller.numpy(),\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"G\" : G,\n",
    "        \n",
    "        \"model\" : model,\n",
    "\n",
    "        \"psnr_lr\" : psnr( validate.get(\"lr\"),  validate.get(\"sr_resized\")),\n",
    "        \"ssim_lr\" : ssim(validate.get(\"lr\"),  validate.get(\"sr_resized\"), multichannel=True),\n",
    "\n",
    "        \"psnr_hr_4\" : psnr( validate.get(\"hr_resized\"),  validate.get(\"sr_resized\"), data_range = 255),\n",
    "        \"ssim_hr_4\" : ssim(validate.get(\"hr_resized\"),  validate.get(\"sr_resized\"), multichannel=True),\n",
    "        \n",
    "        \"psnr_hr\" : psnr( validate.get(\"hr\"),  validate.get(\"sr\")),\n",
    "        \"ssim_hr\" : ssim(validate.get(\"hr\"),  validate.get(\"sr\"), multichannel=True),\n",
    "\n",
    "        \"psnr_bic_hr\" : psnr( validate.get(\"hr\"),  validate.get(\"bic\")),\n",
    "        \"ssim_bic_hr\" : ssim( validate.get(\"hr\"),  validate.get(\"bic\"), multichannel=True),\n",
    "    }\n",
    "    return data\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] read 20 from DIV2K/DIV2K_valid_LR_difficult/\n",
      "[TL] read 20 from DIV2K/DIV2K_valid_HR/\n"
     ]
    }
   ],
   "source": [
    "###====================== PRE-LOAD DATA ===========================###\n",
    "valid_hr_img_list = sorted(tl.files.load_file_list(path=config.VALID.hr_img_path, regx='.*.png', printable=False))[:20]\n",
    "valid_lr_img_list = sorted(tl.files.load_file_list(path=config.VALID.lr_img_path, regx='.*.png', printable=False))[:20]\n",
    "\n",
    "valid_lr_imgs = tl.vis.read_images(valid_lr_img_list, path=config.VALID.lr_img_path, n_threads=32)\n",
    "\n",
    "valid_hr_imgs = tl.vis.read_images(valid_hr_img_list, path=config.VALID.hr_img_path, n_threads=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPyPlot(validate_data, resized = True):\n",
    "\n",
    "\n",
    "    label = 'SSIM: {:.2f}, sk_psnr:{:.2f} PSNR: {:.2f}'\n",
    "\n",
    "    if resized: # show the images at size == the size of the input LR image\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(17, 12),\n",
    "                             sharex=True, sharey=True)\n",
    "        ax = axes.ravel()\n",
    "        \n",
    "        ax[0].imshow(validate_data.get(\"images\").get(\"lr\"))\n",
    "        ax[0].set_xlabel(label.format(1.00, 100.0, 100.0))\n",
    "        ax[0].set_title('valid LR image')\n",
    "        \n",
    "        ax[1].imshow(validate_data.get(\"images\").get(\"sr_resized\"))\n",
    "        ax[1].set_xlabel(label.format(validate_data.get(\"ssim_lr\"), validate_data.get(\"psnr_lr\"), validate_data.get(\"PSNR_lr\")))\n",
    "        ax[1].set_title('generated image resized *-4 vs LR image')\n",
    "        \n",
    "        ax[2].imshow(validate_data.get(\"images\").get(\"hr_resized\"))\n",
    "        ax[2].set_xlabel(label.format(1.00, 100.0, 100.0))\n",
    "        ax[2].set_title('valid HR resized *-4')      \n",
    "        \n",
    "        ax[3].imshow(validate_data.get(\"images\").get(\"sr_resized\"))\n",
    "        ax[3].set_xlabel(label.format(validate_data.get(\"ssim_hr_4\"), validate_data.get(\"psnr_hr_4\"), validate_data.get(\"PSNR_hr_4\")))\n",
    "        ax[3].set_title('generated image resized *-4 vs HR resized')\n",
    "        \n",
    "    else: \n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(17, 12),\n",
    "                             sharex=True, sharey=True)\n",
    "        ax = axes.ravel()\n",
    "    \n",
    "        ax[0].imshow(validate_data.get(\"images\").get(\"hr\"))\n",
    "        ax[0].set_xlabel(label.format(1.00, 100.0, 100.0))\n",
    "        ax[0].set_title('valid HR image')\n",
    "\n",
    "        ax[1].imshow(validate_data.get(\"images\").get(\"bic\"))\n",
    "        ax[1].set_xlabel(label.format(validate_data.get(\"ssim_bic_hr\"), validate_data.get(\"psnr_bic_hr\"), validate_data.get(\"PSNR_bic_hr\")))\n",
    "        ax[1].set_title('bicubic interpolation *4 vs HR')\n",
    "\n",
    "        ax[2].imshow(validate_data.get(\"images\").get(\"sr\"))\n",
    "        ax[2].set_xlabel(label.format(validate_data.get(\"ssim_hr\"), validate_data.get(\"psnr_hr\"), validate_data.get(\"PSNR_bic_hr\")))\n",
    "        ax[2].set_title('generated image vs HR')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_names(a):\n",
    "    return int(a.replace(\".h5\",\"\").split(\"-\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_three(l):\n",
    "    return [i for i in set((randrange(l), randrange(l), randrange(l), randrange(l), randrange(l)))][:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"g-830-base.h5\", \"g-830-cyclic.h5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "l = len(valid_hr_img_list)\n",
    "\n",
    "for image in rand_three(l):\n",
    "    validate_array = []\n",
    "    for model in models:\n",
    "        valid_lr_img = valid_lr_imgs[image]\n",
    "        valid_hr_img = valid_hr_imgs[image]\n",
    "        image_name = valid_hr_img_list[image]\n",
    "        \n",
    "        ev = evaluate(\"checkpoint\", model, valid_lr_img, valid_hr_img, image_name, G = G)\n",
    "        \n",
    "        G = ev.pop(\"G\", G)\n",
    "        validate_array.append(ev) \n",
    "        \n",
    "    with open(\"logs/\" + image_name + \".json\", mode='w', encoding='utf-8') as f:\n",
    "        json.dump(validate_array, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Input  _inputlayer_2: [1, None, None, 3]\n",
      "[TL] Conv2d conv2d_38: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d_39: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_34: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_40: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_35: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_18: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_41: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_36: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_42: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_37: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_19: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_43: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_38: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_44: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_39: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_20: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_45: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_40: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_46: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_41: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_21: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_47: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_42: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_48: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_43: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_22: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_49: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_44: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_50: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_45: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_23: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_51: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_46: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_52: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_47: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_24: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_53: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_48: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_54: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_49: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_25: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_55: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_50: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_56: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_51: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_26: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_57: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_52: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_58: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_53: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_27: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_59: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_54: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_60: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_55: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_28: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_61: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_56: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_62: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_57: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_29: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_63: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_58: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_64: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_59: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_30: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_65: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_60: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_66: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_61: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_31: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_67: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_62: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_68: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_63: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_32: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_69: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_64: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_70: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_65: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_33: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_71: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_66: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_34: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_72: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] SubpixelConv2d  subpixelconv2d_3: scale: 2 act: relu\n",
      "[TL] Conv2d conv2d_73: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] SubpixelConv2d  subpixelconv2d_4: scale: 2 act: relu\n",
      "[TL] Conv2d conv2d_74: n_filter: 3 filter_size: (1, 1) strides: (1, 1) pad: SAME act: tanh\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Model name 'generator' has already been used by another model. Please change the model name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-dd68217d16e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimage_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_hr_img_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mev_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_downsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"checkpoint\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"g-830-base.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_hr_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"G\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mev_cyclic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_downsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"checkpoint\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"g-830-cyclic.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_hr_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-c9ed593fe162>\u001b[0m in \u001b[0;36mevaluate_downsample\u001b[0;34m(checkpoint_dir, model, valid_hr_img, image_name, G, save_dir)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/tendai/huawei/srgan/model.py\u001b[0m in \u001b[0;36mget_G\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"generator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorlayer/models/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_global_model_name_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0;34m'Model name \\'%s\\' has already been used by another model. Please change the model name.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                 )\n\u001b[1;32m    174\u001b[0m             \u001b[0m_global_model_name_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Model name 'generator' has already been used by another model. Please change the model name."
     ]
    }
   ],
   "source": [
    "l = len(valid_hr_img_list)\n",
    "\n",
    "validate_ds_array_base = []\n",
    "validate_ds_array_cyclic = []\n",
    "\n",
    "for image in rand_three(l):    \n",
    "    valid_hr_img = valid_hr_imgs[image]\n",
    "    image_name = valid_hr_img_list[image]\n",
    "\n",
    "    ev_base = evaluate_downsample(\"checkpoint\", \"g-830-base.h5\", valid_hr_img, image_name, G = G)\n",
    "    G = ev.pop(\"G\", G)\n",
    "    ev_cyclic = evaluate_downsample(\"checkpoint\", \"g-830-cyclic.h5\", valid_hr_img, image_name, G = G)\n",
    "    \n",
    "    validate_ds_array_cyclic.append(ev_cyclic) \n",
    "    validate_ds_array_base.append(ev_base)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(validate_ds_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "createPyPlot(validate, resized = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "createPyPlot(validate, resized = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
